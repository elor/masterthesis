\section{Laufzeitanalyse von Parsivald-Simulationen}
\label{runtime}

Für Parsivald-Simulationen ergeben sich verschiedene Einschränkungen, etwa in der Größe des Simulationsraumes oder der Laufzeit von MD-Simulationen, welche die Zahl der Parallelen Worker beschränken und die parallele Laufzeit erhöhen.
Nachfolgend wird deshalb eine Laufzeitanalyse von Parsivald unter Berücksichtigung diverser Größen durchgeführt.
\todo{Disclaimer, dass mit ``Raumgröße'' die Größe der Oberfläche gemeint ist, da es sich hier um Oberflächenabscheidungen handelt.}
Wie bei Laufzeitanalysen üblich, werden Laufzeiten mit $T$ bezeichnet und sollten nicht mit Temperaturen verwechselt werden.

\subsection{Ereignis-Laufzeit $T_\text{E}$}

Die Auswahl eines Ereignisses in KMC-Algorithmen ist mit einer Laufzeit~$T_\text{E}$ verbunden, die sich aus der Laufzeit von Suchoperationen $T_\text{KMC}$, der Laufzeit von Serialisierungen und Deserialisierungen zur Datenübertragung zwischen Host und Worker $T_\text{Ser.}$ und $T_\text{Des.}$ sowie der Laufzeit für die \todo{Wurde die Konnektivitätsprüfung vorgestellt?}Konnektivitätsprüfung $T_\text{Konn.}$ zusammen setzt.

\begin{equation}
T_\text{E} = T_\text{KMC} + T_\text{Ser.} + T_\text{Des.} + T_\text{Konn.}
\end{equation}
Dabei überwiegt $T_\text{Konn.}$ mit \BigO{N^2} für $N$ Atome in der MD-Box gegenüber den anderen Operationen, welche theoretisch mit \BigO{N} skalieren.
$T_\text{KMC}$ skaliert durch das Caching-Verhaltens des benutzten Octrees tatsächlich linear mit $N$, wo hingegen die C++-Standard-Bibliothek durch ihr Buffer-Verhalten für annähernd konstante Laufzeiten von $T_\text{Ser.}$ und $T_\text{Des.}$ sorgt.
Eine Reduktion von $T_\text{E}$ ist somit nur durch die Auslagerung der Konnektivitätsprüfung in die Worker-Prozesse oder durch die Nutzung einer Delaunay-Triangulation anstelle des Octrees möglich, wodurch die Konnektivität in \BigO{N} geprüft werden kann.

\subsection{Ereignis-Durchsatz $R_\text{E}$}

Als Ereignis-Durchsatz wird nachfolgend die Zahl der vom Host zur MD-Berechnung bereit gestellten Ereignisse pro Zeiteinheit bezeichnet.
Damit handelt es sich eigentlich um eine Rate von Ereignissen, die jedoch nicht mit der Ereignisrate aus dem KMC-Formalismus (Abschnitt~\ref{kmc}) verwechselt werden sollte.
Der Wert des Ereignis-Durchsatzes beschreibt hier die maximal mögliche Zahl von Ereignissen pro Zeiteinheit anstatt der Zahl der tatsächlich berechneten Ereignisse.
In der aktuellen Implementierung führt ein serieller Host-Prozess alle Vor- und Nachbereitungen von Ereignissen durch, weshalb sich der Ereignis-Durchsatz als reziproker Wert von $T_\text{E}$ ergibt:

\begin{equation}
  R_\text{E} = \frac{1}{T_\text{E}}
\end{equation}

\subsection{MD-Laufzeit $T_\text{MD}$}

Die Zeit zur Durchführung einer molekulardynamischen Simulationen beim Worker wird im Folgenden als MD-Laufzeit $T_\text{MD}$ bezeichnet.
Sie ist hauptsächlich von den benutzten Kraftfeldern abhängig, wird jedoch auch durch die durchgeführten MD-Operationen, die Relaxationszeit, sowie die Größe der MD-Box und die damit verbundene Zahl der Atome beeinflusst.
Vom KMC-Algorithmus ist sie hingegen unabhängig.

\subsection{Worker-Laufzeit $T_\text{worker}$}

Die Worker-Laufzeit ergibt sich aus der MD-Laufzeit und der Zeit zur Deserialisierung der Anfangsbedingungen und zur Serialisierung der Ergebnisse.
Da hier die MD-Laufzeit dominiert, wird diese zur Berechnung abgeleiteter Größen genutzt.
\begin{equation}
  T_\text{worker} = T_\text{Ser.} + T_\text{Des.} + T_\text{MD} \approx T_\text{MD}
\end{equation}

\subsection{Serielle Laufzeit $T_1$}

Die serielle Laufzeit $T_1$ bezeichnet die Laufzeit eines Programmes unter Nutzung eines einzigen Prozesses.
Damit ist sie von der vernachlässigbaren Laufzeit zur einmaligen Vorbereitung $T_\text{start}$ und den Ereignis- und MD-Laufzeiten $T_\text{E}$ und $T_\text{MD}$ sowie der Zahl der Ereignisse $N_\text{E}$ abhängig.

\begin{align}
  T_1 & = T_\text{start} + N_\text{E} \cdot (T_\text{E} + T_\text{MD}) \\
      & \approx N_\text{E} T_\text{E} + N_\text{E} T_\text{MD}
\end{align}

\subsection{Anzahl der parallelen Prozesse $p$}

Ein wichtiges Maß für die Effizienz eines parallelen Prozess ist die Zahl der parallelen Prozesse $p$.
Für Parsivald bezeichnet $p-1$ die mittlere Zahl der aktiven MD-Prozesse, wobei der Hauptprozess separat betrachtet wird.
Für $p$ ergeben sich obere Schranken $p_\text{max}$ in der maximalen Bedeckung der Oberfläche mit MD-Boxen sowie im Ereignis-Durchsatz, welche mit unbegrenzten Workerpools erreicht werden können.

Für kleine Simulationsräume lässt sich die maximale Anzahl von Ereignissen $p_\text{max,1}-1$ aus der dichtesten Packung von meist quadratischen MD-Boxen der Breite $w_\text{MD}$, Tiefe $d_\text{MD}$ und Fläche $A_\text{MD} = w_\text{MD} \cdot d_\text{MD}$ im Simulationsraum ($w_\text{sim}$, $d_\text{sim}$, $A_\text{sim}$) abschätzen:
\begin{equation}
  p_\text{max,1} = \left\lfloor\frac{w_\text{sim}}{w_\text{MD}}\right\rfloor \cdot \left\lfloor\frac{d_\text{sim}}{d_\text{MD}}\right\rfloor + 1 \approx \left\lfloor\frac{A_\text{sim}}{A_\text{MD}}\right\rfloor + 1
  \label{eq:pmax1}
\end{equation}
Bei großen Simulationsräumen ergibt sich die obere Schranke aus dem Ereignis-Durchsatz des Hauptprozesses in Verbindung mit der Laufzeit der MD-Simulationen:
\begin{equation}
  p_\text{max,2} = R_\text{E} \cdot T_\text{MD} + 1 = \frac{T_\text{MD}}{T_\text{E}} + 1
  \label{eq:pmax2}
\end{equation}
Somit bestimmt sich $p_\text{max}$ als Minimum der beiden oberen Schranken $p_\text{max,1/2}$ .
\begin{align}
  %% p_\text{max} & = \min(p_\text{max,1}, p_\text{max,2}) \\
  %%              & = \min\left(\left\lfloor\frac{A_\text{sim}}{A_\text{MD}}\right\rfloor, \frac{T_\text{MD}}{T_\text{E}}\right)
  p_\text{max} = \min\left(\left\lfloor\frac{A_\text{sim}}{A_\text{MD}}\right\rfloor, \frac{T_\text{MD}}{T_\text{E}}\right) + 1
\end{align}

\subsection{Workerdichte $\rho_\text{worker}$}

Ein Parsivald-spezifisches Leistungsmaß ergibt sich mit der Workerdichte, welche das Verhältnis der mittleren Anzahl der aktiven Worker $p-1$ zur maximalen Zahl gleichzeitiger Ereignisse im Simulationsraum $p_\text{max,1}-1$ beschreibt und somit auch für verschiedene Kraftfelder und Substratgrößen vergleichbar ist.
Aufgrund der stochastischen Verteilung der Ereignisorte werden selbst in idealen Simulationsläufen nur zwischen \SI{10}{\percent} und \SI{40}{\percent} für $\rho_\text{worker}$ erreicht.
\begin{equation}
  \rho_\text{worker} = \frac{p - 1}{p_\text{max,1} - 1}
\end{equation}

\subsection{Parallele Laufzeit $T_p$}

Die parallele Laufzeit $T_p$ bezeichnet die Laufzeit eines Programmes unter Nutzung von $p$ parallelen Prozessen.
Neben den MD-Workern muss dabei auch der Hauptprozess beachtet werden, der die KMC-Operationen verwaltet, sodass die MD-Simulationen auf nur $p-1$ Prozesse aufgeteilt werden.
Der Hauptprozess und die Worker synchronisieren sich dabei nach jedem Parsivald-Schritt, also nach jeder vollständigen KMC-Simulation, sodass das Maximum der Host- und der Worker-Laufzeiten die parallele Laufzeit bildet.

\begin{equation}
  T_p = T_\text{start} + \max\left(N_\text{E} T_\text{E}, \frac{N_\text{E} T_\text{MD}}{p-1}\right) \approx \frac{N_\text{E} T_\text{MD}}{p-1}
\end{equation}

\subsection{Speedup $S_p$}

Beim Speedup handelt es sich um das Verhältnis der linearen Laufzeit zur parallelen Laufzeit.
Damit ist er ein in der Laufzeitanalyse übliches Maß für die Effizienz paralleler Algorithmen.
\begin{align}
  S_p & = \frac{T_1}{T_p} = \left(p-1\right) \frac{\left(T_\text{E} + T_\text{MD}\right)}{T_\text{MD}} \\
      & = p - \frac{p_\text{max,2} - p}{p_\text{max,2} - 1}
\end{align}
Bei Parsivald-Läufen mit wenigen Workern ist der Speedup somit sublinear, nimmt aber für große Simulationsräume mit $p = p_\text{max,2}$ theoretisch einen idealen Speedup von $S_\text{max} = p_\text{max,2} = p$ an.
%% Dabei ist nicht $S_\text{max}$ selbst maximal, sondern die Zahl der parallelen Prozesse.

\subsection{Parallele Effizienz $E_p$}

Die parallele Effizienz $E_p$ ist als Verhältnis aus dem Speedup $S_p$ zur Zahl der Prozesse $p$ definiert:
\begin{equation}
  E_p = \frac{S_p}{p} = 1 - \frac{p_\text{max,2} - p}{p (p_\text{max,2} - 1)}
\end{equation}
Somit ergibt auch der Speedup für $p = p_\text{max,2}$ mit $E_\text{max} = 1$ eine ideale Effizienz, die auf volle Auslastung aller Prozesse bei vernachlässigbarem Overhead hinweist\todo{so what?}.

%% \subsection{Abschätzung des parallelen Anteils $P$ (Parallelisierbarkeit)}

%% Aus den oben gegebenen Formeln lässt sich der serielle Anteil $S$ der Laufzeit anhand der maximalen Zahl der Worker $p = p_\text{max,2}$ abschätzen:
%% \begin{equation}
%%   S = \frac{T_\text{E}}{T_\text{MD} + T_\text{E}} = \frac{1}{p + 1}
%% \end{equation}
%% Aus der Beziehung $S + P = 1$ ergibt sich eine Parallelisierbarkeit $P$ von Parsivald aus der Zahl der Worker $p$ wie folgt:
%% \begin{equation}
%%   P = \frac{p}{p+1}
%% \end{equation}

\subsection{Auswertung der Laufzeitparameter}

\todo{um ein paar Zeilen kürzen?}
Die Parallelisierung von Parsivald-Simulationen lässt sich über die Größe der als quadratisch angenommen Simulationsräume $w_\text{sim}$, die Ereignis-Laufzeit $T_\text{E}$ und die MD-Laufzeit $T_\text{MD}$ beeinflussen.
Einen geringeren Einfluss haben die Größe der MD-Box $w_\text{MD}$ und die mittlere Workerdichte~$\rho_\text{worker}$ des Prozesses, welche ergänzend in Anhang~\ref{appendix_runtime} untersucht werden.
Im allgemeinen Fall muss ein Gleichgewicht zwischen $T_\text{E}$, $T_\text{MD}$, $w_\text{sim}$ und $p$ gefunden werden.

Abbildung~\ref{fig:densitymaxsize} stellt den Einfluss von $T_\text{E}$ und $T_\text{MD}$ auf die maximale Größe des Simulationsraumes $w_\text{eff}$ für effiziente Berechnungen dar.
Dabei werden für effiziente Simulationen Workerdichten oberhalb von des Wertes von \SI{10}{\percent} angenommen, der aus Erfahrungen mit dem Parsivald-Modell stammt und durch die stochastisch verteilte Überdeckung von MD-Boxen bedingt ist.
Es zeigt sich, dass mit steigender MD-Laufzeit sowie mit sinkender Ereignis-Laufzeit die Größe des Simulationsraumes für effiziente Simulationen zunimmt, wobei theoretisch auch Räume mit \SI{2x2}{\micro\meter} effizient simuliert werden können.
In der aktuellen Implementierung liegt $T_\text{E}$ bei \SI{30}{\milli\second}, wobei für EAM-Potentiale mit $T_\text{MD}=\SI{5}{\second}$ Simulationsräume bis zu \SI{150x150}{\nano\meter} effizient simuliert werden können.
Für ReaxFF-basierte Simulationsläufe mit $T_\text{MD}=\SI{50}{\second}$ steigt dieser Wert auf \SI{400x400}{\nano\meter}.

\begin{figure}[p]
  \captionsetup[subfigure]{singlelinecheck=false}
  \def\subfigwidth{7cm}
  \begin{subfigure}[t]{\subfigwidth}
    \includegraphics[width=\textwidth]{densitybymdtime}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{\subfigwidth}
    \includegraphics[width=\textwidth]{maxsizebymdtime}
  \end{subfigure}

  \caption{Einfluss der MD-Laufzeit auf die maximale Workerdichte und das Maximum der Simulationsgröße für effiziente Rechnungen ($\rho_\text{worker} > \SI{10}{\percent}$)}
  \label{fig:densitymaxsize}

\end{figure}

Diese Beschränkung von $w_\text{eff}$ ergibt sich aus dem Ereignis-Durchsatz $R_\text{E}$ und der daraus resultierenden maximalen Anzahl paralleler Worker $p_\text{max}$.\continuehere
Wie Abbildung~\ref{fig:workersbytime} zu entnehmen ist, steigt das Maximum der parallelen Prozesse mit der MD-Laufzeit, weshalb größere Simulationsräume möglich werden.
Andererseits steigt es mit sinkender Ereignis-Laufzeit und somit mit steigendem Ereignis-Durchsatz, weshalb effiziente Datenstrukturen und eine Optimierung des Host-Worker-Protokolles notwendig sind.
Eine Extrapolation der Werte aus Abbildung~\ref{figure:workersbytime} ergibt für Simulationsräume einer Größe von \SI{1x1}{\micro\meter} die Notwendigkeit von mehr als \num{10000} parallelen Prozessen, die aktuell nur mit hochparallelen Rechnerclustern möglich sind.
Der Skalierungs-Vorteil gegenüber parallelen MD-Simulationen liegt dann im geringen Grad an Kommunikation zwischen den einzelnen Workern.

\begin{figure}[p]

  \captionsetup[subfigure]{singlelinecheck=false}
  \def\subfigwidth{7cm}
  \begin{subfigure}[t]{\subfigwidth}
    \includegraphics[width=\textwidth]{workersbymdtime}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{\subfigwidth}
    \includegraphics[width=\textwidth]{workersbykmctime}
  \end{subfigure}

  \caption{Einfluss der Ereignis-Laufzeit $T_\text{E}$ und der MD-Laufzeit $T_\text{MD}$ auf die maximale Zahl paralleler Prozesse $p_\text{max}$}
  \label{fig:workersbytime}

\end{figure}

Abbildung~\ref{fig:runtimebytime} stellt zuletzt den Einfluss der MD-Laufzeit und der Ereignis-Laufzeit auf die parallelen Laufzeit $T_\infty$ unter Annahme einer maximalen Zahl von Workern dar, wie sie in Abbildung~\ref{fig:workersbytime} dargestellt sind.
Es zeigt sich eine konstante Laufzeit für Simulationsräume mit~$w_\text{sim} < w_\text{eff}$.
Für größere Räume nimmt die Laufzeit linear mit der Größe der simulierten Oberfläche zu.
Die Laufzeit effizienter Parsivald-Simulationen ist also unabhängig von ihrer Größe.
Für große Räume mit $w_\text{sim} > w_\text{eff}$ ist die Simulationszeit außerdem von der MD-Laufzeit unabhängig.
Das klingt nach einem Widerspruch, doch heben sich hier $T_p \sim T_\text{MD}$ und $p \sim T_\text{MD}$ über die Beziehung $T_p \sim p^{-1}$ gegenseitig auf.

\begin{figure}[p]

  \captionsetup[subfigure]{singlelinecheck=false}
  \def\subfigwidth{7cm}
  \begin{subfigure}[t]{\subfigwidth}
    \includegraphics[width=\textwidth]{runtimebymdtime}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{\subfigwidth}
    \includegraphics[width=\textwidth]{runtimebykmctime}
  \end{subfigure}

  \caption{Einfluss der Ereignis-Laufzeit $T_\text{E}$ und der MD-Laufzeit $T_\text{MD}$ auf die minimale Laufzeit $T_\infty$ einer Parsivald-Simulation}
  \label{fig:runtimebytime}

\end{figure}

\subsection{Fazit}

Für kleine Simulationsräume ermöglicht Parsivald konstante parallele Laufzeiten $T_p$ unabhängig von der Größe der Oberfläche, wohingegen für große Simulationsräume eine ideale parallele Effizienz $E_\text{max} = 1$ für bis zu $p_\text{max}$ parallele Prozesse möglich ist.
Damit eignet sich Parsivald für effiziente atomistische Simulation von Abscheidungsprozessen.

%% Wählt man $p = p_\text{max} / \rho_\text{worker}$ mit der erwarteten Workerdichte $\rho_\text{worker}$, so kann man über die Gleichungen~\ref{eq:pmax1} und~\ref{eq:pmax2} $w_\text{sim}$ so bestimmen, dass die Simulation...

%% Aus $T_\text{MD}$ und $T_\text{E}$ lässt sich bei einer unbegrenzten Anzahl von Workern über die Beziehung $p_\text{max,1} = p_\text{max,2}$ aus Gleichungen~\ref{eq:pmax1} und~\ref{eq:pmax2} die ideale Raumgröße für effiziente Prozesse $w_{\text{sim}_\text{eff.}}$ bestimmen.
%% Bei dieser Größe sind alle Prozesse voll ausgelastet, jedoch benötigt die Simulation eine minimale parallele Laufzeit~$T_p$, was aus der Wahl der Raumgröße am Knick von $p_\text{max}$ resultiert (Abbildung~\ref{fig:workersbytime}).
%% Für eine geringere Zahl an Workern lässt sich über $p = p_\text{max,1}$ aus Gleichung~\ref{eq:pmax1} der größtmögliche Raum wählen, der in minimaler Simulationszeit simuliert werden kann.
%% Damit bietet Parsivald für kleine Simulationsräume minimale parallele Laufzeit, während für größere Simulationsräume ideale parallele Effizienz von $E_\text{max} = 1$ für $p_\text{max}$ Prozesse vorliegt.
