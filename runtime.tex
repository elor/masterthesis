\section{Laufzeitanalyse von Parsivald-Simulationen}
\label{runtime}

Für Parsivald-Simulationen ergeben sich verschiedene Einschränkungen, etwa in der Größe des Simulationsraumes oder der Laufzeit von MD-Simulationen, welche die Zahl der Parallelen Worker beschränken und die parallele Laufzeit erhöhen.
Nachfolgend wird deshalb eine Laufzeitanalyse von Parsivald unter Berücksichtigung diverser Größen durchgeführt.
\todo{Disclaimer, dass mit ``Raumgröße'' die Größe der Oberfläche gemeint ist, da es sich hier um Oberflächenabscheidungen handelt.}
Wie bei Laufzeitanalysen üblich, werden Laufzeiten mit $T$ bezeichnet und sollten nicht mit Temperaturen verwechselt werden.

\subsection{Ereignis-Laufzeit $T_\text{E}$}

Die Auswahl eines Ereignisses in KMC-Algorithmen ist mit einer Laufzeit~$T_\text{E}$ verbunden, die sich aus der Laufzeit von Suchoperationen $T_\text{KMC}$, der Laufzeit von Serialisierungen und Deserialisierungen zur Datenübertragung zwischen Host und Worker $T_\text{Ser.}$ und $T_\text{Des.}$ sowie der Laufzeit für die \todo{Wurde die Konnektivitätsprüfung vorgestellt?}Konnektivitätsprüfung $T_\text{Konn.}$ zusammen setzt.

\begin{equation}
T_\text{E} = T_\text{KMC} + T_\text{Ser.} + T_\text{Des.} + T_\text{Konn.}
\end{equation}
Dabei überwiegt $T_\text{Konn.}$ mit \BigO{N^2} für $N$ Atome in der MD-Box gegenüber den anderen Operationen, welche theoretisch mit \BigO{N} skalieren.
$T_\text{KMC}$ skaliert durch das Caching-Verhaltens des benutzten Octrees tatsächlich linear mit $N$, wo hingegen die C++-Standard-Bibliothek durch ihr Buffer-Verhalten für annähernd konstante Laufzeiten von $T_\text{Ser.}$ und $T_\text{Des.}$ sorgt.
Eine Reduktion von $T_\text{E}$ ist somit nur durch die Auslagerung der Konnektivitätsprüfung in die Worker-Prozesse oder durch die Nutzung einer Delaunay-Triangulation anstelle des Octrees möglich, wodurch die Konnektivität in \BigO{N} geprüft werden kann.

\subsection{Ereignis-Durchsatz $R_\text{E}$}

Als Ereignis-Durchsatz wird nachfolgend die Zahl der vom Host zur MD-Berechnung bereit gestellten Ereignisse pro Zeiteinheit bezeichnet.
Damit handelt es sich eigentlich um eine Rate von Ereignissen, die jedoch nicht mit der Ereignisrate aus dem KMC-Formalismus (Abschnitt~\ref{kmc}) verwechselt werden sollte.
Der Wert des Ereignis-Durchsatzes beschreibt hier die maximal mögliche Zahl von Ereignissen pro Zeiteinheit anstatt der Zahl der tatsächlich berechneten Ereignisse.
In der aktuellen Implementierung führt ein serieller Host-Prozess alle Vor- und Nachbereitungen von Ereignissen durch, weshalb sich der Ereignis-Durchsatz als reziproker Wert von $T_\text{E}$ ergibt:

\begin{equation}
  R_\text{E} = \frac{1}{T_\text{E}}
\end{equation}

\subsection{MD-Laufzeit $T_\text{MD}$}

Die Zeit zur Durchführung einer molekulardynamischen Simulationen beim Worker wird im Folgenden als MD-Laufzeit $T_\text{MD}$ bezeichnet.
Sie ist hauptsächlich von den benutzten Kraftfeldern abhängig, wird jedoch auch durch die durchgeführten MD-Operationen, die Relaxationszeit, sowie die Größe der MD-Box und die damit verbundene Zahl der Atome beeinflusst.
Vom KMC-Algorithmus ist sie hingegen unabhängig.

\subsection{Worker-Laufzeit $T_\text{worker}$}

Die Worker-Laufzeit ergibt sich aus der MD-Laufzeit und der Zeit zur Deserialisierung der Anfangsbedingungen und zur Serialisierung der Ergebnisse.
Da hier die MD-Laufzeit dominiert, wird diese zur Berechnung abgeleiteter Größen genutzt.
\begin{equation}
  T_\text{worker} = T_\text{Ser.} + T_\text{Des.} + T_\text{MD} \approx T_\text{MD}
\end{equation}

\subsection{Serielle Laufzeit $T_1$}

Die serielle Laufzeit $T_1$ bezeichnet die Laufzeit eines Programmes unter Nutzung eines einzigen Prozesses.
Damit ist sie von der vernachlässigbaren Laufzeit zur einmaligen Vorbereitung $T_\text{start}$ und den Ereignis- und MD-Laufzeiten $T_\text{E}$ und $T_\text{MD}$ sowie der Zahl der Ereignisse $N_\text{E}$ abhängig.

\begin{align}
  T_1 & = T_\text{start} + N_\text{E} \cdot (T_\text{E} + T_\text{MD}) \\
      & \approx N_\text{E} T_\text{E} + N_\text{E} T_\text{MD}
\end{align}

\subsection{Anzahl der parallelen Prozesse $p$}

Ein wichtiges Maß für die Effizienz eines parallelen Prozess ist die Zahl der parallelen Prozesse $p$.
Für Parsivald bezeichnet $p-1$ die mittlere Zahl der aktiven MD-Prozesse, wobei der Hauptprozess separat betrachtet wird.
Für $p$ ergeben sich obere Schranken $p_\text{max}$ in der maximalen Bedeckung der Oberfläche mit MD-Boxen sowie im Ereignis-Durchsatz, welche mit unbegrenzten Workerpools erreicht werden können.

Für kleine Simulationsräume lässt sich die maximale Anzahl von Ereignissen $p_\text{max,1}-1$ aus der dichtesten Packung von meist quadratischen MD-Boxen der Breite $w_\text{MD}$, Tiefe $d_\text{MD}$ und Fläche $A_\text{MD} = w_\text{MD} \cdot d_\text{MD}$ im Simulationsraum ($w_\text{sim}$, $d_\text{sim}$, $A_\text{sim}$) abschätzen:
\begin{equation}
  p_\text{max,1} = \left\lfloor\frac{w_\text{sim}}{w_\text{MD}}\right\rfloor \cdot \left\lfloor\frac{d_\text{sim}}{d_\text{MD}}\right\rfloor + 1 \approx \left\lfloor\frac{A_\text{sim}}{A_\text{MD}}\right\rfloor + 1
  \label{eq:pmax1}
\end{equation}
Bei großen Simulationsräumen ergibt sich die obere Schranke aus dem Ereignis-Durchsatz des Hauptprozesses in Verbindung mit der Laufzeit der MD-Simulationen:
\begin{equation}
  p_\text{max,2} = R_\text{E} \cdot T_\text{MD} + 1 = \frac{T_\text{MD}}{T_\text{E}} + 1
  \label{eq:pmax2}
\end{equation}
Somit bestimmt sich $p_\text{max}$ als Minimum der beiden oberen Schranken $p_\text{max,1/2}$ .
\begin{align}
  %% p_\text{max} & = \min(p_\text{max,1}, p_\text{max,2}) \\
  %%              & = \min\left(\left\lfloor\frac{A_\text{sim}}{A_\text{MD}}\right\rfloor, \frac{T_\text{MD}}{T_\text{E}}\right)
  p_\text{max} = \min\left(\left\lfloor\frac{A_\text{sim}}{A_\text{MD}}\right\rfloor, \frac{T_\text{MD}}{T_\text{E}}\right) + 1
  \label{eq:pmax}
\end{align}

\subsection{Workerdichte $\rho_\text{worker}$}

Ein Parsivald-spezifisches Leistungsmaß ergibt sich mit der Workerdichte, welche das Verhältnis der mittleren Anzahl der aktiven Worker $p-1$ zur maximalen Zahl gleichzeitiger Ereignisse im Simulationsraum $p_\text{max,1}-1$ beschreibt und somit auch für verschiedene Kraftfelder und Substratgrößen vergleichbar ist.
Aufgrund der stochastischen Verteilung der Ereignisorte werden in Simulationsläufen nur zwischen \SI{10}{\percent} und \SI{40}{\percent} für $\rho_\text{worker}$ erreicht.
\begin{equation}
  \rho_\text{worker} = \frac{p - 1}{p_\text{max,1} - 1}
  \label{eq:workerdensity}
\end{equation}

\subsection{Parallele Laufzeit $T_p$}

Die parallele Laufzeit $T_p$ bezeichnet die Laufzeit eines Programmes unter Nutzung von $p$ parallelen Prozessen.
Neben den MD-Workern muss dabei auch der Hauptprozess beachtet werden, der die KMC-Operationen verwaltet, sodass die MD-Simulationen auf nur $p-1$ Prozesse aufgeteilt werden.
Durch Synchronisation von Hauptprozess und Workerpools bildet sich die parallele Laufzeit aus dem Maximum der Host- und Worker-Laufzeiten.

\begin{equation}
  T_p = T_\text{start} + \max\left(N_\text{E} T_\text{E}, \frac{N_\text{E} T_\text{MD}}{p-1}\right) \approx \frac{N_\text{E} T_\text{MD}}{p-1}
\end{equation}

\subsection{Speedup $S_p$}

Beim Speedup handelt es sich um ein für Laufzeitanalysen übliches Maß, welches sich aus dem Verhältnis der linearen Laufzeit zur parallelen Laufzeit bildet.
\begin{align}
  S_p & = \frac{T_1}{T_p} = \left(p-1\right) \frac{\left(T_\text{E} + T_\text{MD}\right)}{T_\text{MD}} \\
      & = p - \frac{p_\text{max,2} - p}{p_\text{max,2} - 1}
\end{align}
Bei Parsivald-Läufen mit wenigen Workern ist der Speedup somit sublinear, nimmt aber für große Simulationsräume mit $p = p_\text{max,2}$ theoretisch einen idealen Speedup von $S_\text{max} = p_\text{max,2} = p$ an.
%% Dabei ist nicht $S_\text{max}$ selbst maximal, sondern die Zahl der parallelen Prozesse.

\subsection{Parallele Effizienz $E_p$}

Die parallele Effizienz $E_p$ ist als Verhältnis aus dem Speedup $S_p$ zur Zahl der Prozesse $p$ definiert:
\begin{equation}
  E_p = \frac{S_p}{p} = 1 - \frac{p_\text{max,2} - p}{p (p_\text{max,2} - 1)}
\end{equation}
Somit ergibt sich für $p = p_\text{max,2}$ mit $E_\text{max} = 1$ eine ideale Effizienz, die auf volle Auslastung aller Prozesse bei vernachlässigbarem Overhead hinweist\todo{so what?}.

%% \subsection{Abschätzung des parallelen Anteils $P$ (Parallelisierbarkeit)}

%% Aus den oben gegebenen Formeln lässt sich der serielle Anteil $S$ der Laufzeit anhand der maximalen Zahl der Worker $p = p_\text{max,2}$ abschätzen:
%% \begin{equation}
%%   S = \frac{T_\text{E}}{T_\text{MD} + T_\text{E}} = \frac{1}{p + 1}
%% \end{equation}
%% Aus der Beziehung $S + P = 1$ ergibt sich eine Parallelisierbarkeit $P$ von Parsivald aus der Zahl der Worker $p$ wie folgt:
%% \begin{equation}
%%   P = \frac{p}{p+1}
%% \end{equation}

\subsection{Auswertung der Laufzeitparameter}

\todo{um ein paar Zeilen kürzen?}
Die Parallelisierung von Parsivald-Simulationen lässt sich über die Größe der als quadratisch angenommen Simulationsräume $w_\text{sim}$, die Ereignis-Laufzeit $T_\text{E}$ und die MD-Laufzeit $T_\text{MD}$ beeinflussen.
Einen geringeren Einfluss haben die Größe der MD-Box $w_\text{MD}$ und die mittlere Workerdichte~$\rho_\text{worker}$ des Prozesses, welche ergänzend in Anhang~\ref{appendix_runtime} untersucht werden.
Im allgemeinen Fall muss ein Gleichgewicht zwischen $T_\text{E}$, $T_\text{MD}$, $w_\text{sim}$ und $p$ gefunden werden.

Das Skalierungsverhalten von Parsivald teilt sich anhand der Raumgröße $w_\text{sim}$ in zwei Bereiche ein.
Für ``kleine Räume'' $w_\text{sim} \le w_\text{eff}$ determiniert $p_\text{max,1}$ das Skalierungsverhalten, wohingegen für ``große Räume'' $w_\text{sim} \ge w_\text{eff}$ $p_\text{max,2}$ dominiert.
Die effiziente Raumgröße $\le w_\text{eff}$ entspricht dabei einer kritischen Raumgröße, an der ein Knick in den Abbildungen~\ref{fig:densitymaxsize},\ref{fix:workersbytime} und~\ref{fig:runtimebytime} erkennbar ist.

Die effiziente Größe $w_\text{eff}$ lässt sich anhand der maximalen Workerdichte $\rho_\text{worker,max}$ bestimmen.
Liegt diese oberhalb einer aus Erfahrungen gewonnenen Grenze von \SI{10}{\percent}, wird von einem effizienten Prozess im Sinne der parallelen Effizienz ausgegangen.
Es gilt dann aufgrund der Beziehungen aus Gleichungen~\ref{eq:pmax} und~\ref{eq:workerdensity}:
\begin{align}
  w_\text{eff} & \sim T_\text{MD}     \\
  w_\text{eff} & \sim T_\text{E}^{-1}
\end{align}
Für die aktuelle Implementierung ergibt sich für EAM-Potentiale mit \SI{5}{\second} MD-Laufzeit die effiziente Größe als $w_\text{eff} = \SI{150}{\nano\meter}$ und für ReaxFF-Potentiale mit $T_\text{MD}=\SI{50}{\second}$ als $w_\text{eff} = \SI{400}{\nano\meter}$.
Unter Optimierung des Hostprozesses zu $T_\text{E} = \SI{3}{\milli\second}$ sind theoretisch \SI{2x2}{\micro\meter} große Räume effizient berechenbar, doch ist hierbei die Zahl der notwendigen Prozessoren zu beachten.

\begin{figure}[p]
  \captionsetup[subfigure]{singlelinecheck=false}
  \def\subfigwidth{7cm}
  \begin{subfigure}[t]{\subfigwidth}
    \includegraphics[width=\textwidth]{densitybymdtime}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{\subfigwidth}
    \includegraphics[width=\textwidth]{maxsizebymdtime}
  \end{subfigure}

  \caption{Einfluss der MD-Laufzeit auf die maximale Workerdichte und das Maximum der Simulationsgröße für effiziente Rechnungen ($\rho_\text{worker} > \SI{10}{\percent}$)}
  \label{fig:densitymaxsize}

\end{figure}

Dieser Einfluss ist auch in Abbildung~\ref{fig:workersbytime} zu erkennen, bei der eine Verschiebung von $w_\text{eff}$ mit einer Verschiebung des Knicks einher geht und somit mehr Prozesse für große Räume zulässt.
Durch Extrapolierung erhält man mehr als \num{10000} Prozesse zur effizienten Simulation von \SI{1x1}{\micro\meter} großen Räumen, welche aktuell jedoch nur von wenigen Rechenclustern bereit gestellt werden können.
Die maximale Zahl der Prozesse in kleinen Räumen wird hingegen ausschließlich über die Größe der MD-Box $w_\text{MD}$ bestimmt, welche zur Reduktion der Gesamt-Laufzeit nach Möglichkeit minimal gewählt wird.

\begin{figure}[p]

  \captionsetup[subfigure]{singlelinecheck=false}
  \def\subfigwidth{7cm}
  \begin{subfigure}[t]{\subfigwidth}
    \includegraphics[width=\textwidth]{workersbymdtime}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{\subfigwidth}
    \includegraphics[width=\textwidth]{workersbykmctime}
  \end{subfigure}

  \caption{Einfluss der Ereignis-Laufzeit $T_\text{E}$ und der MD-Laufzeit $T_\text{MD}$ auf die maximale Zahl paralleler Prozesse $p_\text{max}$}
  \label{fig:workersbytime}

\end{figure}

Für die Gesamt-Laufzeit ergibt sich ein konstantes Skalierungsverhalten für kleine Räume, während große Räume lineares Verhalten mit der Größe der Oberfläche zeigen.
Die Laufzeit $T_p$ ist also unabhängig von $w_\text{sim}$, solange $w \le w_\text{eff}$ gilt.
Für große Räume mit $w_\text{sim} > w_\text{eff}$ ist die Gesamt-Laufzeit außerdem von der MD-Laufzeit unabhängig.
Das klingt nach einem Widerspruch, doch heben sich hier $T_p \sim T_\text{MD}$ und $p \sim T_\text{MD}$ über die Beziehung $T_p \sim p^{-1}$ gegenseitig auf.

\begin{figure}[p]

  \captionsetup[subfigure]{singlelinecheck=false}
  \def\subfigwidth{7cm}
  \begin{subfigure}[t]{\subfigwidth}
    \includegraphics[width=\textwidth]{runtimebymdtime}
  \end{subfigure}
  \hfill
  \begin{subfigure}[t]{\subfigwidth}
    \includegraphics[width=\textwidth]{runtimebykmctime}
  \end{subfigure}

  \caption{Einfluss der Ereignis-Laufzeit $T_\text{E}$ und der MD-Laufzeit $T_\text{MD}$ auf die minimale Laufzeit $T_\infty$ einer Parsivald-Simulation}
  \label{fig:runtimebytime}

\end{figure}

\subsection{Fazit}

Für kleine Simulationsräume ermöglicht Parsivald konstante parallele Laufzeiten $T_p$ unabhängig von der Größe der Oberfläche, wohingegen für große Simulationsräume eine ideale parallele Effizienz $E_\text{max} = 1$ für bis zu $p_\text{max}$ parallele Prozesse möglich ist.
Damit eignet sich Parsivald für effiziente atomistische Simulation von Abscheidungsprozessen.
Mit $w_\text{eff}$ wird dabei der größte Simulationsraum beschrieben, der in minimaler Laufzeit simuliert werden kann.
\todo{klar machen, dass es sich um eine Analyse handelt, keine Auswertung}
